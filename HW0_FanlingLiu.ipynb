{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdk1rlsGSLQR"
   },
   "source": [
    "## **HW#0-STA208-S24: Getting Started / Warmup Exercises**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rK8MpFKvCWp"
   },
   "source": [
    "### Part II: Some Exercises (turn in for credit)\n",
    "\n",
    "These exercises are meant to recall basic geometric interpretation underlying concepts from linear algebra and to get some practice in using basic numpy/python.\n",
    "\n",
    "\n",
    "1) Add a new text cell to this notebook right below the fomulation of this problem 1 (in particular, split the cell - see keyboard shortcuts in the tools dropdown menu for the command) and add your answers to this problem there. Use LATEX for writing formulas.\n",
    "\n",
    "Suppose $u$ is a $d$-dimensional vector that is normal to a hyperplane $H$. Consider the $(d \\times d)$-matrix\n",
    "\n",
    "$$U := I_d - \\frac{1}{\\|u\\|^2}uu^\\top.$$\n",
    "\n",
    "a) Show that for any $d$-dimensional vector $v$, the vector $Uv$ (matrix multiplication) lies in $H$. [HINT: Show this by using the property of a normal vector.]\n",
    "\n",
    "b) Provide a geometric interpretation of the vector $Uv$ (i.e. describe how it relates geometrically to $v$).\n",
    "\n",
    "c) With $I_d$ denoting the $(d \\times d)$_identity matrix, the matrix\n",
    "\n",
    "$$U^* := I_d - \\frac{2}{\\|u\\|^2}uu^\\top$$\n",
    "\n",
    "is called *elementary reflector* (or sometimes *Hausholder transformation*). Compare the vector $U^*v$ to $Uv$ and explain the name *elementary reflector*. [HINT: Drawing a figure for $d=2$ might help.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: a) Given the matrix $U$ defined as $U = I_d - \\frac{1}{\\|u\\|^2}uu^\\top$, and the vector $v$, the operation $Uv$ is given by:\n",
    "\n",
    "$$\n",
    "Uv = v - \\frac{1}{\\|u\\|^2}uu^\\top v\n",
    "$$\n",
    "\n",
    "Multiplying both sides by $u^\\top$ from the left:\n",
    "\n",
    "$$\n",
    "u^\\top (Uv) = u^\\top \\left( v - \\frac{1}{\\|u\\|^2}uu^\\top v \\right)\n",
    "$$\n",
    "\n",
    "Expanding the right-hand side:\n",
    "\n",
    "$$\n",
    "u^\\top (Uv) = u^\\top v - u^\\top \\left( \\frac{1}{\\|u\\|^2}uu^\\top v \\right)\n",
    "$$\n",
    "\n",
    "Since $u^\\top u = \\|u\\|^2$, this simplifies to:\n",
    "\n",
    "$$\n",
    "u^\\top (Uv) = u^\\top v - \\frac{\\|u\\|^2}{\\|u\\|^2}u^\\top v = u^\\top v - u^\\top v = 0\n",
    "$$\n",
    "\n",
    "Therefore, $u^\\top (Uv) = 0$, which implies $Uv$ is orthogonal to $u$ and hence lies in the hyperplane $H$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: b) The matrix $U$ projects $v$ onto the hyperplane $H$. The vector $Uv$ can be seen as the component of $v$ that lies entirely in the hyperplane $H$ orthogonal to $u$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: c) Given the matrix $U^*$ defined as $U^* = I_d - \\frac{2}{\\|u\\|^2}uu^\\top$, and the vector $v$, given the formula above that $Uv = v - \\frac{1}{\\|u\\|^2}uu^\\top v$, the operation $U^*v$ is given by:\n",
    "\n",
    "$$\n",
    "U^*v = v - \\frac{2}{\\|u\\|^2}uu^\\top v = Uv-\\frac{1}{\\|u\\|^2}uu^\\top v\n",
    "$$\n",
    "\n",
    "As we proved before, Uv lies on hyperplane $H$, which is the component of $v$ that lies entirely in the hyperplane $H$ orthogonal to $u$. On the other hand, $\\frac{1}{\\|u\\|^2}uu^\\top v$ calculates the projection of $v$ onto the direction of $u$. This projection is the component of $v$ that is parallel to $u$. $Uv-\\frac{1}{\\|u\\|^2}uu^\\top v$, i.e. by subtracting the projection $Uv$ from $v$, the result is a vector that has been \"reflected\" across the hyperplane. The subtraction effectively removes the component of $v$ that is parallel to $u$ and replaces it with its inverse, while the component of $v$ that lies in the hyperplane $H$ remains unchanged. That's why it called element reflector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVr5gTextkv6"
   },
   "source": [
    "2) Use numpy to do the computations in this problem. To this end, use this notebook, add a code cell right below the formulation of this problem and put your solutions there.\n",
    "\n",
    "a) Define $u = (1,2,3,3,2,1)$, $v = (1,2,3,4,5,6).$\n",
    "- Compute the matrix $U = I - \\frac{1}{\\|u\\|^2}uu^\\top$ and find $Uv$ (print both, the matrix $U$ and the vector $Uv$)\n",
    "- Compute $U^* = I - \\frac{2}{\\|u\\|^2}uu^\\top$ and find $U^*v$ (print both, the matrix $U^*$ and the vector $U^*v$).\n",
    "\n",
    "b)  Consider the real value\n",
    "$\\alpha = \\frac{\\langle u, Uv-U^*v\\rangle}{\\|u\\|\\cdot\\|Uv - U^*v\\|}.$\n",
    "- Make a conjecture of what the value of $\\alpha$ is (use your geometric intuition - again, drawing a figure in $d=2$ should help).\n",
    "- Compute $\\alpha$, and explain the value you obtain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96428571 -0.07142857 -0.10714286 -0.10714286 -0.07142857 -0.03571429]\n",
      " [-0.07142857  0.85714286 -0.21428571 -0.21428571 -0.14285714 -0.07142857]\n",
      " [-0.10714286 -0.21428571  0.67857143 -0.32142857 -0.21428571 -0.10714286]\n",
      " [-0.10714286 -0.21428571 -0.32142857  0.67857143 -0.21428571 -0.10714286]\n",
      " [-0.07142857 -0.14285714 -0.21428571 -0.21428571  0.85714286 -0.07142857]\n",
      " [-0.03571429 -0.07142857 -0.10714286 -0.10714286 -0.07142857  0.96428571]]\n",
      "[-0.5 -1.  -1.5 -0.5  2.   4.5]\n",
      "[[ 0.92857143 -0.14285714 -0.21428571 -0.21428571 -0.14285714 -0.07142857]\n",
      " [-0.14285714  0.71428571 -0.42857143 -0.42857143 -0.28571429 -0.14285714]\n",
      " [-0.21428571 -0.42857143  0.35714286 -0.64285714 -0.42857143 -0.21428571]\n",
      " [-0.21428571 -0.42857143 -0.64285714  0.35714286 -0.42857143 -0.21428571]\n",
      " [-0.14285714 -0.28571429 -0.42857143 -0.42857143  0.71428571 -0.14285714]\n",
      " [-0.07142857 -0.14285714 -0.21428571 -0.21428571 -0.14285714  0.92857143]]\n",
      "[-2. -4. -6. -5. -1.  3.]\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "import numpy as np\n",
    "# 1)\n",
    "u = np.array([1, 2, 3, 3, 2, 1])\n",
    "v = np.array([1, 2, 3, 4, 5, 6])\n",
    "I = np.eye(len(u))\n",
    "norm_u_squared = np.dot(u,u)\n",
    "U = I - (np.outer(u, u) / norm_u_squared)\n",
    "Uv = np.dot(U, v)\n",
    "print(U)\n",
    "print(Uv)\n",
    "# 2)\n",
    "U_star = I - 2*(np.outer(u, u) / norm_u_squared)\n",
    "U_star_v = np.dot(U_star, v)\n",
    "print(U_star)\n",
    "print(U_star_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: b) Let's decompose the formula:\n",
    "$$\n",
    "Uv - U^*v = Uv - (v - \\frac{2}{\\|u\\|^2}uu^\\top v) = Uv - (Uv-\\frac{1}{\\|u\\|^2}uu^\\top v) = \\frac{1}{\\|u\\|^2}uu^\\top v\n",
    "$$\n",
    "which is the projection of $v$ on $u$, which could has the same direction of $u$ or opposite the direction of $u$.\n",
    "\n",
    "Thus, the numerator $<u,\\frac{1}{\\|u\\|^2}uu^\\top v>$ is the product of the norm of $u$ and the norm of the difference between $Uv$ and  $U^*v$, which is the scaled squared norm of u, with the sign positive or negative.\n",
    "Since the denominator is also the the difference between $Uv$ and  $U^*v$, so $\\alpha$ will be either 1 or -1, depending on the orientation of $u$ with respect to $Uv - U^*v$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "dot_product = np.dot(u, Uv - U_star_v)\n",
    "norm_u = np.linalg.norm(u)\n",
    "norm_difference = np.linalg.norm(Uv - U_star_v)\n",
    "alpha = dot_product / (norm_u * norm_difference)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: In this computation, the alpha is 1, which means the orientation of $u$ align with respect to $Uv - U^*v$, the v is lie on the opposite sides of the hyperplane $H$ compared to u."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xnd0M6TYiATk"
   },
   "source": [
    "3) Consider the matrix $UU^\\top$ with $U$ from above. We are now concerned about the eigenvalues of $UU^\\top$.\n",
    "\n",
    "- Make a conjecture about the values of the eigenvalues of $UU^\\top$ (positive, negative, zero, certain specific values??).\n",
    "\n",
    "- Compute the eigenvalues using numpy and iterprete the values that you find.\n",
    "\n",
    "- Explain why $UU^\\top = UU = U$, i.e. $U$ is idempotent.\n",
    "\n",
    "- Let $V$ be the $(6 \\times 3)$-matrix consisting of the first three columns of $U$. Is $V$ also idempotent? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 ANS: Given that $U$ projects vectors onto a hyperplane orthogonal to $u$, reducing components along $u$ to zero while preserving components orthogonal to $u$, the expected eigenvalues of $UU^\\top$ are:\n",
    "- **1** for dimensions unaffected by $U$, indicating directions orthogonal to $u$.\n",
    "- **0** for the dimension aligned with $u$, where the projection nullifies components.\n",
    "\n",
    "Negative or complex eigenvalues are unlikely for $U$ as it does not entail operations (like rotation or reflection) that could produce such eigenvalues, being a straightforward projection matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00 -2.14027754e-17  1.00000000e+00  1.00000000e+00\n",
      "  1.00000000e+00  1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# 2)\n",
    "UU_T = np.dot(U, U.T)\n",
    "eigenvalues_UU_T, _ = np.linalg.eig(UU_T)\n",
    "print(eigenvalues_UU_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96428571, -0.07142857, -0.10714286, -0.10714286, -0.07142857,\n",
       "        -0.03571429],\n",
       "       [-0.07142857,  0.85714286, -0.21428571, -0.21428571, -0.14285714,\n",
       "        -0.07142857],\n",
       "       [-0.10714286, -0.21428571,  0.67857143, -0.32142857, -0.21428571,\n",
       "        -0.10714286],\n",
       "       [-0.10714286, -0.21428571, -0.32142857,  0.67857143, -0.21428571,\n",
       "        -0.10714286],\n",
       "       [-0.07142857, -0.14285714, -0.21428571, -0.21428571,  0.85714286,\n",
       "        -0.07142857],\n",
       "       [-0.03571429, -0.07142857, -0.10714286, -0.10714286, -0.07142857,\n",
       "         0.96428571]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UU_T.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 ANS: The eigenvalues of $UU^\\top$ are \\(1, 0, 1, 1, 1, 1\\), with the multiple 1s indicating directions orthogonal to $u$ that remain unaffected by the projection, preserving their magnitude. The eigenvalue approximately 0 signifies the dimension along $u$ being reduced to zero by the projection, reflecting the reduction in dimensionality as vectors align with the hyperplane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 ANS: The matrix $U = I_d - \\frac{1}{\\|u\\|^2}uu^\\top$ is an idempotent matrix that $UU = U$. This is a characteristic feature of projection matrices. This idempotency stems from $U$'s function to project vectors onto a hyperplane orthogonal to $u$. The essence of projection ensures that once a vector is projected (flattened against the hyperplane), subsequent projections by $U$ maintain the vector unchanged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96428571 -0.07142857 -0.10714286]\n",
      " [-0.07142857  0.85714286 -0.21428571]\n",
      " [-0.10714286 -0.21428571  0.67857143]\n",
      " [-0.10714286 -0.21428571 -0.32142857]\n",
      " [-0.07142857 -0.14285714 -0.21428571]\n",
      " [-0.03571429 -0.07142857 -0.10714286]]\n",
      "[[ 0.94642857 -0.10714286 -0.16071429 -0.05357143 -0.03571429 -0.01785714]\n",
      " [-0.10714286  0.78571429 -0.32142857 -0.10714286 -0.07142857 -0.03571429]\n",
      " [-0.16071429 -0.32142857  0.51785714 -0.16071429 -0.10714286 -0.05357143]\n",
      " [-0.05357143 -0.10714286 -0.16071429  0.16071429  0.10714286  0.05357143]\n",
      " [-0.03571429 -0.07142857 -0.10714286  0.10714286  0.07142857  0.03571429]\n",
      " [-0.01785714 -0.03571429 -0.05357143  0.05357143  0.03571429  0.01785714]]\n",
      "[[ 0.96428571 -0.07142857 -0.10714286]\n",
      " [-0.07142857  0.85714286 -0.21428571]\n",
      " [-0.10714286 -0.21428571  0.67857143]]\n"
     ]
    }
   ],
   "source": [
    "V = U[:, :3]\n",
    "\n",
    "# Compute V*V^T and V^T*V to analyze if V is idempotent\n",
    "VV_T = np.dot(V, V.T)\n",
    "V_T_V = np.dot(V.T, V)\n",
    "\n",
    "print(V)\n",
    "print(VV_T)\n",
    "print(V_T_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 ANS: Examining the idempotency of a non-square matrix $V$, composed of the first three columns of $U$, through $VV^\\top$ and $V^\\top V$, reveals that idempotency, typically defined as $A^2 = A$ for square matrices, is not applicable to $V$. Specifically:\n",
    "- $VV^\\top$ yields a $6 \\times 6$ matrix, suggesting transformations within a $6$-dimensional space, but does not equate to $V$ or an identity matrix, indicating the absence of idempotent characteristics in $V$.\n",
    "- Conversely, $V^\\top V$ produces a $3 \\times 3$ matrix, which, despite aligning more closely with $V$'s structural essence, fails to fulfill the idempotency criterion by not replicating $V$ or an identity matrix.\n",
    "\n",
    "Therefore, $V$ does not qualify as idempotent. This analysis underscores $V$'s role in facilitating transformations across its subspaces, diverging from the square matrix requirement for idempotency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh5vxaTPinBn"
   },
   "source": [
    "4) Some numpy practice: With $U = (U_{ij})_{i,j=1,\\ldots,6}$ from above do the following:\n",
    "\n",
    "- Find the largest and smallest off-diagonal elements of $UU^\\top$.\n",
    "\n",
    "- Find the largest and smallest diagonal elements of $UU^\\top$.\n",
    "\n",
    "- Compute the value $max_i \\sum_{j} |U_{ij}|$.\n",
    "\n",
    "- Print the elements of the second column of $UU^\\top$ below the diagonal.\n",
    "\n",
    "- Verify idempotence of $U$ by showing that $UU - U = 0$ (where the $0$ on the right hand side is the $0$-matrix).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03571428571428571\n",
      "-0.3214285714285715\n",
      "0.9642857142857143\n",
      "0.6785714285714286\n",
      "1.6428571428571428\n",
      "[-0.21428571 -0.21428571 -0.14285714 -0.07142857]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "# 1) Find the largest and smallest off-diagonal elements of UU^T\n",
    "off_diagonal_elements = UU_T[~np.eye(UU_T.shape[0], dtype=bool)] # Extracting off-diagonal elements\n",
    "largest_off_diagonal = np.max(off_diagonal_elements)\n",
    "smallest_off_diagonal = np.min(off_diagonal_elements)\n",
    "print(largest_off_diagonal)\n",
    "print(smallest_off_diagonal)\n",
    "\n",
    "# 2) Find the largest and smallest diagonal elements of UU^T\n",
    "diagonal_elements = np.diag(UU_T)\n",
    "largest_diagonal = np.max(diagonal_elements)\n",
    "smallest_diagonal = np.min(diagonal_elements)\n",
    "print(largest_diagonal)\n",
    "print(smallest_diagonal)\n",
    "\n",
    "# 3) Compute the value max_i sum_{j} |U_{ij}|\n",
    "max_sum_abs_U_ij = np.max(np.sum(np.abs(U), axis=1))\n",
    "print(max_sum_abs_U_ij)\n",
    "\n",
    "# 4) Print the elements of the second column of UU^T below the diagonal\n",
    "second_column_below_diagonal = UU_T[2:, 1]\n",
    "print(second_column_below_diagonal)\n",
    "\n",
    "# 5) # Verify idempotence of U by showing that UU - U = 0\n",
    "idempotence = np.dot(U, U.T) - U\n",
    "print(np.allclose(idempotence, 0))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
